{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bab7336b",
   "metadata": {},
   "source": [
    "# Lab session taught by Oladimeji Mudele"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae33928",
   "metadata": {},
   "source": [
    "Welcome to this lab session on Time series modeling for air pollution monitoring with a focus on the\n",
    "calibration of low-cost sensors.\n",
    "\n",
    "This lab session is based on the data and methods provided in the study by [Ellen M. Considine et al](https://www.sciencedirect.com/science/article/pii/S0269749120365222).\n",
    "\n",
    "Rather than focus on code efficiency, software engineering practices, or theory of machine learning models, this course focuses on the **thought processes** (as generalised as possible) that apply to tackling many data science problems. Don't worry if you don't understanding certain nuances around syntax or code implementations. These problems are always easier to tackle. My advice is that you focus on the \"WHY?\".\n",
    "\n",
    "The interesting part of this course module is that, rather than work with cleaned data and do our explorations and modeling from there, we will try to simulate the real-life scenario of merging data from multple sources (sensors) and time periods, and also engineer the features we need for our prediction task.\n",
    "\n",
    "In certain events in data science, you might be lucky to have your data stuctured and prepared for you. Most often, this is not the case.\n",
    "\n",
    "Welcome to the world of data science."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb41868",
   "metadata": {},
   "source": [
    "In this notebook, we will prepare the training and test data. In ths process we will go through the following steps:\n",
    "\n",
    "- **Understading the problem**: This leads us to the question: \"**What data do I need?**\"\n",
    "- **Diving into the data**: This is simply looking at your data (each column), and asking yourself, what does it mean? Why do I need it? How would I use it for my task? What units are the data expressed in?\n",
    "- Aligning the different axis and features in the multi-source/multitemporal data\n",
    "- **Cleaning**: dealing with invalid and missing values. For example, in the case of our project, the low-cost Canary-S (CS) sensor readings register -1 as invalid values and the authors of our reference literature mentioned 1500 units of PM2.5 as the maximum threhold. We need to handle these cases. Also, we need to check for rows with missing values.\n",
    "- **Merging**: pull data from multiple sources into a single frame.\n",
    "- **Features crafting**: Based on our understanding of the problem we are trying to solve, it might be useful to take some of the information in th dsta and use them to craft features we believe will udeful for our model to learn what it needs to learn in other to produce the best results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc52b44",
   "metadata": {},
   "source": [
    "# WHAT IS OUR PROBLEM?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90b46b6",
   "metadata": {},
   "source": [
    "We have PM2.5 readings from low cost sensors and we want to learn a model that maps them to \"true\" readings from reference FEM (AirNow) sensors . "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf57b60",
   "metadata": {},
   "source": [
    "# WHAT DATA DO WE NEED?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ec531b",
   "metadata": {},
   "source": [
    "##### The obvious and basic ones:\n",
    "- PM2.5 readings from AirNow sensors\n",
    "- PM2.5 readings from CS sensors\n",
    "\n",
    "##### What other data or features might we need? (Our experiments will determine what is eventually useful\n",
    "- lenght of road with certain radius from sensing location.\n",
    "- Time variables\n",
    "- temperature  \n",
    "- humidity\n",
    "- day of the week (weekend or not)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd096f17",
   "metadata": {},
   "source": [
    "# NOW LET US DIVE INTO CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326d3fff",
   "metadata": {},
   "source": [
    "We need some Python libraries to enable efficient implementations of computations. The libraries we need are `numpy`, `pandas`and the `math`module which is part of the python standard library. For now, please ensure to install both `numpy`and `pandas`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c8c8c3",
   "metadata": {},
   "source": [
    "Now, let us import these libraries into our workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f01f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8537f9a",
   "metadata": {},
   "source": [
    "Now, we are done with preparing ourselves for the data preparation phase. Here we go!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ef4dc4",
   "metadata": {},
   "source": [
    "# TRAINING DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfa5ab7",
   "metadata": {},
   "source": [
    "### Load the data from disk and explain the details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ea6ef2",
   "metadata": {},
   "source": [
    "Let us specify the subfolder in our project folder where you have kept all the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d14310",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"./data/\"  # change this to your own subfolder. Ideally, it should be the same as defined here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99c8e15",
   "metadata": {},
   "source": [
    "In the `data` subfolder, you will find a couple of csv files, the raw training data is in a file named `raw_collocated_data.csv`. Let us load that file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1906b560",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_path = (\n",
    "    data_root + \"raw_collocated_data.csv\"\n",
    ")  # first we define the file location using string concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e950f633",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_training_data = pd.read_csv(\n",
    "    training_data_path\n",
    ")  # Here we load the data as a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ef6515",
   "metadata": {},
   "source": [
    "### So, what are the columns in our data and what do they mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5174bae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_training_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bd7a0d",
   "metadata": {},
   "source": [
    "It is important to ensure that you understandevery variable in the columns of your dataframe. In essense: \n",
    "\n",
    "Why do we need each of these variables (if at all)?\n",
    "\n",
    "In what way do we have to organise the data to make them most useful to us?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc1a607",
   "metadata": {},
   "source": [
    "### Understanding the data content in our dataframe\n",
    "\n",
    "In summary, we need to look at each column and ask ourselves what information it contains, why and how we will need the information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e404e49",
   "metadata": {},
   "source": [
    "CS#: Canary sensor number # <br>\n",
    "AirNow: FEM reference data source\n",
    "\n",
    "\n",
    "`DateTime`: Date and time that data was registered by sensor\n",
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "`PM2_5(NJH CS Collo (CS1)/Canary-S)` : PM2.5 readings from CS1 located at NJH <br>\n",
    "`tempf(NJH CS Collo (CS1)/Canary-S)` : Temperature (Farenheit) readings from CS2 located at NJH <br>\n",
    "`humidity(NJH CS Collo (CS1)/Canary-S)` : Humidity readings from CS1 located at NJH <br>\n",
    "`PM2.5 (NJH/AirNow)`: PM2.5 readings from the reference FEM sensor located at NJH\n",
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "`PM2_5(I-25 Glo Collo (CS2)/Canary-S)` : PM2.5 readings from CS2 sensor located at I-25 Globeville <br>\n",
    "`tempf(I-25 Glo Collo (CS2)/Canary-S)` : Temperature (Farenheit) readings from CS2 located at I-25 Globeville <br>\n",
    "`humidity(I-25 Glo Collo (CS2)/Canary-S)` : Humidity readings from CS2 located at I-25 Globeville <br>\n",
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "`PM2_5(I-25 Glo Collo (CS3)/Canary-S)` : PM2.5 readings from CS3 sensor located at I-25 Globeville <br>\n",
    "`tempf(I-25 Glo Collo (CS3)/Canary-S)` : Temperature (Farenheit) readings from CS3 located at I-25 Globeville <br>\n",
    "`humidity(I-25 Glo Collo (CS3)/Canary-S)` : Humidity readings from CS3 located at I-25 Globeville <br>\n",
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "`PM2_5(I-25 Glo Collo (CS4)/Canary-S)` : PM2.5 readings from CS4 sensor located at I-25 Globeville <br>\n",
    "`tempf(I-25 Glo Collo (CS4)/Canary-S)` : Temperature (Farenheit) readings from CS4 located at I-25 Globeville <br>\n",
    "`humidity(I-25 Glo Collo (CS4)/Canary-S)` : Humidity readings from CS4 located at I-25 Globeville <br>\n",
    "`PM2.5(I-25 Globeville/AirNow)`: PM2.5 readings from the reference FEM sensor located at I-25 Globeville\n",
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "`PM2_5(La Casa Collo (CS5)/Canary-S)` : PM2.5 readings from CS5 sensor located at La Casa <br>\n",
    "`tempf(La Casa Collo (CS5)/Canary-S)` : Temperature (Farenheit) readings from CS5 located at La Casa <br>\n",
    "`humidity(La Casa Collo (CS5)/Canary-S)` : Humidity readings from CS5 located at La Casa <br>\n",
    "`'PM2.5(La Casa/AirNow)`: PM2.5 readings from the reference FEM sensor located at La Casa\n",
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "`PM2_5(Swansea Elementary Collo (CS7)/Canary-S)` : PM2.5 readings from CS5 sensor located at Swansea Elementary<br>\n",
    "`tempf(Swansea Elementary Collo (CS7)/Canary-S)` : Temperature (Farenheit) readings from CS5 located at Swansea Elementary <br>\n",
    "`humidity(Swansea Elementary Collo (CS7)/Canary-S)` : Humidity readings from CS5 located at Swansea Elementary<br>\n",
    "`PM2.5(I-25 Denver/AirNow)`: PM2.5 readings from the reference FEM sensor located at I-25 Denver\n",
    "<hr style=\"border:2px solid gray\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0c422e",
   "metadata": {},
   "source": [
    "### Units of our observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e0477a",
   "metadata": {},
   "source": [
    "Temperature: Fahrenheit <br>\n",
    "Humidity: grams of water vapor per kilogram of air <br>\n",
    "PM2.5:  $µg/m^3$ <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e04bb94",
   "metadata": {},
   "source": [
    "### Checking for data types\n",
    "\n",
    "Similar vairables should be of the same type. E.g PM2.5 measures by all sensors, ideally, should come in the same datatypes. If not, we will have to cast them to a common datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b188ed7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_training_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14ddfdc",
   "metadata": {},
   "source": [
    "Since we have a Date/Time variable/column in our dataframe, it is important to ensure we let pandas know (explicitly) that this particular column column should be treated as a datetime column type.\n",
    "\n",
    "Let us cast the datetime column in our dataframe into a datetime type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2035e87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_training_data[\"DateTime\"] = pd.to_datetime(raw_training_data[\"DateTime\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18789260",
   "metadata": {},
   "source": [
    "As shown below, our `DateTime`column is now of the `datetime64`type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b22295f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_training_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a3c74b",
   "metadata": {},
   "source": [
    "### Is this how our data should be organised/arranged?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8a9ac2",
   "metadata": {},
   "source": [
    "The cell below helps us to acheive this need rearrangement of our data. In the cell, we create a vriable called `full_training_data` where we store our rearranged training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43418c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "i15_reference_reading = \"PM2.5(I-25 Globeville/AirNow)\"\n",
    "\n",
    "full_training_data = pd.DataFrame(\n",
    "    np.vstack(\n",
    "        [\n",
    "            raw_training_data.iloc[:, 1:5],\n",
    "            pd.concat(\n",
    "                [\n",
    "                    raw_training_data.iloc[:, 5:8],\n",
    "                    raw_training_data[i15_reference_reading],\n",
    "                ],\n",
    "                axis=1,\n",
    "            ),\n",
    "            pd.concat(\n",
    "                [\n",
    "                    raw_training_data.iloc[:, 8:11],\n",
    "                    raw_training_data[i15_reference_reading],\n",
    "                ],\n",
    "                axis=1,\n",
    "            ),\n",
    "            raw_training_data.iloc[:, 11:15],\n",
    "            raw_training_data.iloc[:, 15:19],\n",
    "        ]\n",
    "    ),\n",
    "    columns=[\"pm_cs\", \"temp\", \"humidity\", \"pm_airnow\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5462edec",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_training_data[\"date_time\"] = pd.to_datetime(\n",
    "    pd.concat([raw_training_data.iloc[:, 0]] * 5, ignore_index=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7837830",
   "metadata": {},
   "source": [
    "Let is check the columns in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7923bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_training_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd51520f",
   "metadata": {},
   "source": [
    "We now have a dataframe with columns defined as `[\"pm_cs\", \"temp\", \"humidity\", \"pm_airnow\", \"data_time\"]`.\n",
    "\n",
    "`pm_cs`: PM2.5 measured from tne CS sensors (low cost) <br>\n",
    "`pm_airnow`: PM2.5 measured from the AirNow sensors <br>\n",
    "`date_time`: Date and time information <br>\n",
    "`temp`: temperature readings <br>\n",
    "`humidity`: humidity readings from the CS sensors <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4350fa8",
   "metadata": {},
   "source": [
    "Now, let us check the number of rows in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164645f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {len(full_training_data)} rows in our data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bc51a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5712a13a",
   "metadata": {},
   "source": [
    "Time to start adding new features that might be useful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5762bdca",
   "metadata": {},
   "source": [
    "### Adding sensor location label to our data (useful as tag)\n",
    "\n",
    "This helps to keep track of the different sensing locations durihg our data exploration and modeling. \n",
    "\n",
    "Because we have the same reference monitor for the three collocated sensors at i-25 Globeville, we will have to keep track of the `airnow_sensor` and `cs_sensor` differently. Below we create these 2 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adb7b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_sensor = [\"NJH\", \"i25_glo_1\", \"i25_glo_2\", \"i25_glo_3\", \"la_casa\"]\n",
    "cs_sensor_col = np.repeat(\n",
    "    cs_sensor, len(raw_training_data)\n",
    ")  # note that we repeat in accordance to the raw data size.\n",
    "\n",
    "full_training_data[\"cs_sensor\"] = cs_sensor_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9553823",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_training_data[\"airnow_sensor\"] = full_training_data[\"cs_sensor\"].apply(\n",
    "    lambda x: \"i25_glo\" if x in [\"i25_glo_1\", \"i25_glo_2\", \"i25_glo_3\"] else x\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de396d17",
   "metadata": {},
   "source": [
    "So far, we have now defined the following columns in our data: `[\"pm_cs\", \"temp\", \"humidity\", \"pm_airnow\", \"data_time\", \"cs_sensor\", \"airnow_sensor\"]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5614b1d",
   "metadata": {},
   "source": [
    "### Accounting for seasonal and time effects through hour,  month, and weekend variables "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd51316f",
   "metadata": {},
   "source": [
    "Because of daily, weekly, and seasonal variation in atmospheric PM2.5 that may be due to factors beyond temperature and relative humidity, we will extract hour, weekend, and month variables and convert the `hour` and `month`variables into cyclic values by taking the `cosine` and `sine` of $hour*2π/24$  and $month*2π/12$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9c380a",
   "metadata": {},
   "source": [
    "###### Why do we need sine and cosine encoding of time related features?\n",
    "\n",
    "Some data are inherently cyclical. Time is an enaple of such: minutes, hours, seconds, day of week, week of month, month, season, and so on all follow cycles. \n",
    "\n",
    "**How can we let our machine learning model know that a feature is cyclical?** <br>\n",
    "By using sine and cosine transformations\n",
    "\n",
    "In the cell below, I have created a dummy data for each hour in day and have showed how we can tranform the data from linear (1-demensional) to cyclical (2-dimensional using cosine and sine transformations\n",
    "\n",
    "This [reference](https://ianlondon.github.io/blog/encoding-cyclical-features-24hour-time/) gives a good explanation. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b511fe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example that explains cyclical encoding\n",
    "\n",
    "time = [x for x in range(0, 24 + 1)]  # create a dummy list every hour in the data\n",
    "\n",
    "time = time + time  # Concatenate copies of the same list to form 2 days\n",
    "\n",
    "cos_time = [(math.cos(x) * 2 * (math.pi / 24)) for x in time]\n",
    "sin_time = [(math.sin(x) * 2 * (math.pi / 24)) for x in time]\n",
    "\n",
    "fig, [ax1, ax2] = plt.subplots(nrows=1, ncols=2, figsize=(11, 5.5))\n",
    "\n",
    "ax1.plot(time)\n",
    "ax2.scatter(sin_time, cos_time)\n",
    "ax1.set_title(\"Linear\", size=15)\n",
    "ax2.set_title(\"2-D Cosine and Sine\", size=15)\n",
    "ax1.set_ylabel(\"Hour\", size=15)\n",
    "ax1.set_xlabel(\"Sample\", size=15)\n",
    "ax2.set_ylabel(\"Cosine\", size=15)\n",
    "ax2.set_xlabel(\"Sine\", size=15)\n",
    "plt.suptitle(\"Comparing linear and cyclical encoding of time features\", size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bd9c98",
   "metadata": {},
   "source": [
    "Notice the boundary between 24 and 0. In time, we know that 24 and 0 should be the same. Cyclical encoding helps us achieve this behaviour.\n",
    "\n",
    "This approach is one of the ways to handle time information in time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cbdff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_training_data[\"time\"] = full_training_data[\"date_time\"].dt.hour\n",
    "full_training_data[\"month\"] = full_training_data[\"date_time\"].dt.month\n",
    "\n",
    "\n",
    "full_training_data[\"weekend\"] = (\n",
    "    full_training_data[\"date_time\"].dt.dayofweek >= 4\n",
    ").astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e9367c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_training_data[\"sin_time\"] = full_training_data[\"time\"].apply(\n",
    "    lambda x: math.sin(x) * 2 * (math.pi / 24)\n",
    ")\n",
    "full_training_data[\"cos_time\"] = full_training_data[\"time\"].apply(\n",
    "    lambda x: math.cos(x) * 2 * (math.pi / 24)\n",
    ")\n",
    "\n",
    "full_training_data[\"sin_month\"] = full_training_data[\"month\"].apply(\n",
    "    lambda x: math.sin(x) * 2 * (math.pi / 12)\n",
    ")\n",
    "\n",
    "full_training_data[\"cos_month\"] = full_training_data[\"month\"].apply(\n",
    "    lambda x: math.cos(x) * 2 * (math.pi / 12)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be40442",
   "metadata": {},
   "source": [
    "### Dealing with missing values (NaN) and invalid values.\n",
    "\n",
    "We need to rely on the literature or the data provider to undertstand how to filter the data and wghat to filter out and/or keep in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bab092",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We are starting with {len(full_training_data)} observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee92fc6",
   "metadata": {},
   "source": [
    "#### Setting the threshold for invalid values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad38f7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "low = 0  # CS encodes invalid values as -1\n",
    "high = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3ecb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_training_data = full_training_data[\n",
    "    (full_training_data[\"pm_airnow\"] > low)\n",
    "    & (full_training_data[\"pm_cs\"] > low)\n",
    "    & (full_training_data[\"temp\"] > low)\n",
    "    & (full_training_data[\"humidity\"] > low)\n",
    "    & (full_training_data[\"pm_cs\"] < high)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe01abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN values\n",
    "\n",
    "full_training_data = full_training_data.dropna(\n",
    "    subset=[\"pm_cs\", \"temp\", \"humidity\", \"pm_airnow\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a884dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Now we are left with {len(full_training_data)} hourly observation as our training data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2150e1e",
   "metadata": {},
   "source": [
    "### Add road length variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d6ba88",
   "metadata": {},
   "source": [
    "Along with adjusting for variability in time, it is useful to investigate variability in space (location of reference sensors). The position of an air quality sensor within a city, especially relative to known sources of pollution such as highways, is likely to affect the characteristics of the air pollution in that area.\n",
    "\n",
    "In this regard, the authors of our reference study investigated the effects of lengths of different sizes of roads within a certain distance from a monitor. \n",
    "\n",
    "For this particular course, we will including the lenght of arterial (large) roads within 500m (to be tagged `aroad_500`).\n",
    "\n",
    "ALERT: The lengths here could have been measured in kilometers or Miles. What is most important is that they are all measured on the same unit, which we can believe is the case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128add33",
   "metadata": {},
   "source": [
    "The data  we load below provides us with data on lenght of arterial (large) roads within 500m of each monitor locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6840b08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_data = pd.read_csv(data_root + \"road_lengths.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881bbd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c042c780",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before merging road lenghts variables\")\n",
    "full_training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2ca06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_training_data = road_data.merge(full_training_data, on=\"airnow_sensor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15107f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"After merging road lenghts variables. Longitude and latitude information are also added\"\n",
    ")\n",
    "full_training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbda2af2",
   "metadata": {},
   "source": [
    "Now, let look below to ensure that all the columns we need in our data have been added. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7a010c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_training_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49de1d03",
   "metadata": {},
   "source": [
    "### Note about training data preparation\n",
    "\n",
    "This is our training data preparation. Take note that most real life data science objectives require **rigourous data preparation and feature engineeering**. This lesson has shown you a bit of what that looks like. Now we want to save our cleaned data in a `.csv`file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2c819c",
   "metadata": {},
   "source": [
    "### Finally, save the new version of your training data as a `.csv` file\n",
    "\n",
    "We will use this file in the remaining notebooks (for exploratory data analysis and modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04127738",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_training_data.to_csv(data_root + \"cleaned_training.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6825775d",
   "metadata": {},
   "source": [
    "### Now, let us recall have has been done so far.\n",
    "\n",
    "We have taken our training data from its raw state to a cleaned state. Now, it is ready to be used for further tasks. \n",
    "\n",
    "What exactly did we do so far:\n",
    "\n",
    "1. Checked the columns in the data and interpret them.\n",
    "2. Checked the datatypes and cast to the right datatype where necessary.\n",
    "3. Reorganised our data. We collected data for each CS sensor and from the columns that contain them and stacked all these data on top of one another.\n",
    "4. Dealt with missing or invalid data. In our own case we dropped them, in other cases you can input them using heuristics or interpolation.\n",
    "5. Created features to account for seasonal/time effects  (`weekend`, `cos_hour`, `sin_hour`,`cos_month`, `sin_month`).\n",
    "6. merged road lenghts information into our data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99ab9c0",
   "metadata": {},
   "source": [
    "# TEST DATA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1a235b",
   "metadata": {},
   "source": [
    "We need to repeat the process we have implemented above for the test set. In certain cases, we might be lucky enough to have test data that is formatted exactly like our training data (thus needing the same set of cleaning operations as the training data). In other cases, we might not be so lucky. Our  project is one of the latter. This gives us the opportunity to adapt and craft the appropiate set and sequence of operations needed to clean the test data and align it (in features) to the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9997fd3",
   "metadata": {},
   "source": [
    "**What is the man difference between our test data and our training data**\n",
    "\n",
    "Our test set comes in two `.csv` dataframes covering **September - October** and **November - December**, respectively. We need to **merge** these data together and restructure them for our own use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56d1ff4",
   "metadata": {},
   "source": [
    "First, we should load these two dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050a7390",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path_1 = data_root + \"test-set_Sept-Oct.csv\"\n",
    "test_path_2 = data_root + \"test-set_Nov-Dec.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a770932",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_1 = pd.read_csv(test_path_1)\n",
    "test_data_2 = pd.read_csv(test_path_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071449a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_1[\"DateTime\"] = pd.to_datetime(test_data_1[\"DateTime\"])\n",
    "test_data_2[\"DateTime\"] = pd.to_datetime(test_data_2[\"DateTime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03715ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbed66cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9b362a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84b5c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc23145",
   "metadata": {},
   "source": [
    "The first column (Index 0) has the date/time. Columns  1- 4 has the data from CAMP sensor, 5 - 8 has the data from i-25 Denver sensor. Columns 9 and 10 contain the reference PM2.5 for CAMP and i-25 Denver, respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cf352e",
   "metadata": {},
   "source": [
    "Below, I have created a function to help us reorganise our test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed71035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def organise_test_data(df):\n",
    "\n",
    "    \"\"\"\n",
    "    Utility function to organise our test data\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    new_data = pd.DataFrame(\n",
    "        np.vstack(\n",
    "            [\n",
    "                pd.concat(\n",
    "                    [df.iloc[:, 0], df.iloc[:, 1], df.iloc[:, 3:5], df.iloc[:, 9]],\n",
    "                    axis=1,\n",
    "                ),\n",
    "                pd.concat(\n",
    "                    [df.iloc[:, 0], df.iloc[:, 5], df.iloc[:, 7:9], df.iloc[:, 10]],\n",
    "                    axis=1,\n",
    "                ),\n",
    "            ]\n",
    "        ),\n",
    "        columns=[\"date_time\", \"pm_cs\", \"temp\", \"humidity\", \"pm_airnow\"],\n",
    "    )\n",
    "\n",
    "    camp_sensor_column = [\"CAMP\"] * len(df)\n",
    "    denvor_sensor_column = [\"i25_denver\"] * len(df)\n",
    "    new_data[\"airnow_sensor\"] = camp_sensor_column + denvor_sensor_column\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72879e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_stacked_1 = organise_test_data(test_data_1)\n",
    "test_data_stacked_2 = organise_test_data(test_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25629810",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test_data = pd.concat([test_data_stacked_1, test_data_stacked_2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bbbf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test_data[\"cs_sensor\"] = full_test_data[\"airnow_sensor\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9956376",
   "metadata": {},
   "source": [
    "## Now can we filter the NaNs and invalid values from this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c2a3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We are starting with {len(full_test_data)} observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6183fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test_data = full_test_data[\n",
    "    (full_test_data[\"pm_airnow\"] > low)\n",
    "    & (full_test_data[\"pm_cs\"] > low)\n",
    "    & (full_test_data[\"temp\"] > low)\n",
    "    & (full_test_data[\"humidity\"] > low)\n",
    "    & (full_test_data[\"pm_cs\"] < high)\n",
    "]\n",
    "\n",
    "full_test_data = full_test_data.dropna(\n",
    "    subset=[\"pm_cs\", \"temp\", \"humidity\", \"pm_airnow\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912bd9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Now we are left with {len(full_test_data)} hourly observation as our training data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a1591f",
   "metadata": {},
   "source": [
    "## Add time  and month variables to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935ce6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test_data[\"time\"] = full_test_data[\"date_time\"].dt.hour\n",
    "full_test_data[\"month\"] = full_test_data[\"date_time\"].dt.month\n",
    "full_test_data[\"weekend\"] = (full_test_data[\"date_time\"].dt.dayofweek >= 4).astype(\n",
    "    \"int\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48d16c4",
   "metadata": {},
   "source": [
    "##### Cyclical encoding of time and month columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9e6b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test_data[\"sin_time\"] = full_test_data[\"time\"].apply(\n",
    "    lambda x: math.sin(x) * 2 * (math.pi / 24)\n",
    ")\n",
    "full_test_data[\"cos_time\"] = full_test_data[\"time\"].apply(\n",
    "    lambda x: math.cos(x) * 2 * (math.pi / 24)\n",
    ")\n",
    "full_test_data[\"cos_month\"] = full_test_data[\"month\"].apply(\n",
    "    lambda x: math.sin(x) * 2 * (math.pi / 12)\n",
    ")\n",
    "full_test_data[\"sin_month\"] = full_test_data[\"month\"].apply(\n",
    "    lambda x: math.cos(x) * 2 * (math.pi / 12)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722cae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test_data = road_data.merge(full_test_data, on=\"airnow_sensor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7557a4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f796d458",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test_data.to_csv(data_root + \"cleaned_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895d6a9c",
   "metadata": {},
   "source": [
    "Now, we are done with the data cleaning phase"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
