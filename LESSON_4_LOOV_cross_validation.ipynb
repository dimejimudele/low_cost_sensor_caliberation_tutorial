{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f6a4184",
   "metadata": {},
   "source": [
    "Welcome to this lab session 4 on **Time series modeling for air pollution monitoring with a focus on the\n",
    "calibration of low-cost sensors.**\n",
    "\n",
    "This lab session is based on the data and methods provided in the study by [Ellen M. Considine et al](https://www.sciencedirect.com/science/article/pii/S0269749120365222).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e512b8",
   "metadata": {},
   "source": [
    "In the notebook, we will focus on improving our modeling pipeline by considering cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e325cf6",
   "metadata": {},
   "source": [
    "The question we intend to answer here is: How can we improve the experiment pipeline presented in LESSON 3 notebook.\n",
    "\n",
    "To this aim, we present leave-one-location-out cross validation. This cross validation helps us to understand how well our model generalises into new locations corresponding to the same time coverage of our training data.\n",
    "\n",
    "The idea is to split our training data into training and validation by location.\n",
    "\n",
    "**Step-by-step process**\n",
    "\n",
    "- Iterate over the monitor locations\n",
    "- For each location,\n",
    "    - Select data for that location as validation data and deselect these data from training.\n",
    "    - Fit your model on the resulting training data and predict over the validation location.\n",
    "    - Check the model error on validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbe9868",
   "metadata": {},
   "source": [
    "# First, lets import the libraries we will be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d73e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e703a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460e415c",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64da27cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"./data/\"\n",
    "training_data_path = data_root + \"cleaned_training.csv\"\n",
    "test_data_path = data_root + \"cleaned_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98ca87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(training_data_path)\n",
    "test_data = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99523ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9bcb6c",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994ad23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More evaluation metrics can be added to the function\n",
    "def evaluate_model(y, y_hat):\n",
    "    return {\"RMSE\": round(mean_squared_error(y, y_hat, squared=False), 2)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f12fe30",
   "metadata": {},
   "source": [
    "Now, we need to get Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadcbd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"pm_cs\",\n",
    "    \"temp\",\n",
    "    \"humidity\",\n",
    "    \"a_road_500\",\n",
    "    \"sin_time\",\n",
    "    \"cos_time\",\n",
    "    \"sin_month\",\n",
    "    \"cos_month\",\n",
    "]\n",
    "\n",
    "# This is tagged model_4 in our last notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a389dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lolo_validation_errors = {}\n",
    "locations = training_data[\"cs_sensor\"].unique()\n",
    "\n",
    "for leave_sensor in tqdm(locations, total=len(locations)):\n",
    "\n",
    "    train = training_data[training_data[\"cs_sensor\"] != leave_sensor]\n",
    "    validation = training_data[training_data[\"cs_sensor\"] == leave_sensor]\n",
    "\n",
    "    model = RandomForestRegressor()\n",
    "\n",
    "    x_train, y_train = train[features], train[\"pm_airnow\"]\n",
    "    x_val, y_val = validation[features], validation[\"pm_airnow\"]\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    y_hat_val = model.predict(x_val)\n",
    "\n",
    "    error = evaluate_model(y_val, y_hat_val)\n",
    "    lolo_validation_errors[leave_sensor] = error[\"RMSE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6b4030",
   "metadata": {},
   "source": [
    "The location names below shows signify the location that have been left out of training but used only to obtain validation error.\n",
    "\n",
    "| Location| Baseline RMSE| CV Random forest RMSE|\n",
    "  |---|---|---|\n",
    "  |**Train**|---|---|\n",
    "  |NJH | 4.36| 2.26|\n",
    "  |i25_glo_1|6.67|3.13|\n",
    "  |i25_glo_2|4.55|2.72|\n",
    "  |i25_glo_3|5.41|2.37|\n",
    "  |la_casa|6.06|2.4|\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1ba1bf",
   "metadata": {},
   "source": [
    "Leaving I-25 Globeville data out increases our validation error because by removing this monitor location, we exclude samples from three CS sensors in the data. Relative to the full side of our data, this is a lot of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86adba1b",
   "metadata": {},
   "source": [
    "Ideally, if applying LOLO cross validation, you want to apply it to the model evaluation and selection step in our previous notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da06f8f5",
   "metadata": {},
   "source": [
    "We can represent our training performance in terms of the mean and standard deviation of all the cross validation errors as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7216115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"error mean: \", round(np.mean(list(lolo_validation_errors.values())), 2))\n",
    "print(\"error std: \", round(np.std(list(lolo_validation_errors.values())), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9edd48f",
   "metadata": {},
   "source": [
    "This tells us that our training RMSE of `0.85` when we use all the locations in training is too optimistic, especially for the case of generalizing to new locations over the same time period of our training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b4a9e5",
   "metadata": {},
   "source": [
    "A simple way to combine these cross validated models for test/inference would be to average their outputs\n",
    "\n",
    "\n",
    "$final prediction = (prediction_1 + prediction_2 + prediction_3 + ... + prediction_n) / n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43d3d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
